{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dcf9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54547789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 18:40:13.935202: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7ef70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the data\n",
    "#!wget https://github.com/alexeygrigorev/dino-or-dragon/releases/download/data/dino-dragon.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5de8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the file\n",
    "#!unzip dino-dragon.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3465e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset contains around 1900 images of dinos and around 1900 images of dragons.\n",
    "\n",
    "# The dataset contains separate folders for training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e457ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the keras libraries\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d511fc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 18:40:15.534661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 18:40:15.542212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 18:40:15.542882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 18:40:15.543895: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 18:40:15.544325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 18:40:15.544946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 18:40:15.545503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 18:40:16.172269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 18:40:16.172902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 18:40:16.173453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 18:40:16.173974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13795 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "436ac06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # This shows a total of 11,215,873 parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "100e9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.002\n",
    "momentum = 0.8 \n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.8),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2610ea",
   "metadata": {},
   "source": [
    "## Generator and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77d38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe4d1816",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (150, 150)\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f55e43da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get the training data\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    \"./train\",\n",
    "    class_mode='binary',\n",
    "    #seed=1,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3081dbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get the test data\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_ds = test_gen.flow_from_directory(\n",
    "    \"./test\",\n",
    "    class_mode='binary',\n",
    "    #seed=1,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98a86f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 18:40:17.878175: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-11-22 18:40:18.525474: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-22 18:40:18.526733: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-22 18:40:18.526779: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-22 18:40:18.527813: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-22 18:40:18.527938: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 11s 108ms/step - loss: 0.6895 - accuracy: 0.5194 - val_loss: 0.6556 - val_accuracy: 0.4975\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 9s 117ms/step - loss: 0.6104 - accuracy: 0.6098 - val_loss: 0.5487 - val_accuracy: 0.6675\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.5259 - accuracy: 0.7114 - val_loss: 0.4705 - val_accuracy: 0.7132\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.4353 - accuracy: 0.7729 - val_loss: 0.3986 - val_accuracy: 0.7995\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.3767 - accuracy: 0.8237 - val_loss: 0.5129 - val_accuracy: 0.6701\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3635 - accuracy: 0.8243 - val_loss: 0.3731 - val_accuracy: 0.7868\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3178 - accuracy: 0.8595 - val_loss: 0.3232 - val_accuracy: 0.8604\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.2626 - accuracy: 0.8864 - val_loss: 0.3182 - val_accuracy: 0.8426\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.2512 - accuracy: 0.8927 - val_loss: 0.3091 - val_accuracy: 0.8706\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.2299 - accuracy: 0.9059 - val_loss: 0.3507 - val_accuracy: 0.8147\n"
     ]
    }
   ],
   "source": [
    "# Set up and run the training\n",
    "\n",
    "history = model.fit(\n",
    "              train_ds,\n",
    "              epochs=10,\n",
    "              validation_data=test_ds\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c4e2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8240275979042053"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the median of training accuracy for all the epochs for this model\n",
    "np.median(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47f86f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14944561489215988"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the standard deviation of training loss for all the epochs for this model\n",
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2147c7",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65e90a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "aug_train_gen = ImageDataGenerator(\n",
    "                      rescale=1./255,\n",
    "                      rotation_range=40,\n",
    "                      width_shift_range=0.2,\n",
    "                      height_shift_range=0.2,\n",
    "                      shear_range=0.2,\n",
    "                      zoom_range=0.2,\n",
    "                      horizontal_flip=True,\n",
    "                      fill_mode='nearest',\n",
    ")\n",
    "\n",
    "aug_train_ds = aug_train_gen.flow_from_directory(\n",
    "    \"./train\",\n",
    "    class_mode='binary',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b86f149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 15s 192ms/step - loss: 0.4896 - accuracy: 0.7578 - val_loss: 0.6036 - val_accuracy: 0.7690\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 15s 189ms/step - loss: 0.4286 - accuracy: 0.7911 - val_loss: 0.2985 - val_accuracy: 0.8706\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 15s 190ms/step - loss: 0.4123 - accuracy: 0.8049 - val_loss: 0.2943 - val_accuracy: 0.8985\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 15s 188ms/step - loss: 0.3957 - accuracy: 0.8237 - val_loss: 0.4739 - val_accuracy: 0.8198\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 15s 189ms/step - loss: 0.3837 - accuracy: 0.8269 - val_loss: 0.3113 - val_accuracy: 0.8883\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 15s 189ms/step - loss: 0.3583 - accuracy: 0.8363 - val_loss: 0.3043 - val_accuracy: 0.8832\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 15s 189ms/step - loss: 0.3493 - accuracy: 0.8407 - val_loss: 0.4174 - val_accuracy: 0.8503\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 15s 190ms/step - loss: 0.3651 - accuracy: 0.8218 - val_loss: 0.3116 - val_accuracy: 0.8706\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 15s 188ms/step - loss: 0.3607 - accuracy: 0.8344 - val_loss: 0.4158 - val_accuracy: 0.8477\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 15s 189ms/step - loss: 0.3468 - accuracy: 0.8488 - val_loss: 0.3429 - val_accuracy: 0.8706\n"
     ]
    }
   ],
   "source": [
    "# train the model using the augmented training data for another 10 epochs\n",
    "history2 = model.fit(\n",
    "              aug_train_ds,\n",
    "              epochs=10,\n",
    "              validation_data=test_ds\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bdc2ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3773672580718994"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find mean of test loss for all the epochs for the model trained with augmentations\n",
    "np.mean(history2.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42c0fc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8644670128822327"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations\n",
    "np.mean( history2.history['val_accuracy'][5:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a25bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
